{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:53:56.248202Z",
     "end_time": "2023-07-10T11:53:56.258276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:53:56.258276Z",
     "end_time": "2023-07-10T11:54:09.914934Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_path = \"../models/yolov8m-seg.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:54:09.919940Z",
     "end_time": "2023-07-10T11:54:09.927615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "class YOLOSegmentation:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def detect(self, img):\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        results = self.model.predict(source=img.copy(), save=False, save_txt=False)\n",
    "        result = results[0]\n",
    "        segmentation_contours_idx = []\n",
    "        for seg in result.masks.xyn:\n",
    "            seg[:, 0] *= width\n",
    "            seg[:, 1] *= height\n",
    "            segment = np.array(seg, dtype=np.int32)\n",
    "            segmentation_contours_idx.append(segment)\n",
    "        bboxes = np.array(result.boxes.xyxy.cpu(), dtype=\"int\")\n",
    "        class_ids = np.array(result.boxes.cls.cpu(), dtype=\"int\")\n",
    "        scores = np.array(result.boxes.conf.cpu(), dtype=\"float\").round(2)\n",
    "        return bboxes, class_ids, segmentation_contours_idx, scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:54:09.935620Z",
     "end_time": "2023-07-10T11:54:09.952855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "classes_ids = [\n",
    "    2, # Car\n",
    "    7, # Truck\n",
    "    5, # Bus\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:54:09.946812Z",
     "end_time": "2023-07-10T11:54:09.966849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def extract_contours(folder: str, output_dir: str, Segmentator: YOLOSegmentation, transform_to_drawings=False) -> None:\n",
    "    for image_name in os.listdir(folder)[:]:\n",
    "        if not (image_name.endswith(\".jpg\") or image_name.endswith(\".jpeg\")):\n",
    "            continue\n",
    "        start_path = folder + '/' + image_name\n",
    "        end_path = f\"{output_dir}/\"\n",
    "        os.makedirs(end_path, exist_ok=True)\n",
    "\n",
    "        img = cv2.imread(start_path)\n",
    "        if img is None:\n",
    "            print(Exception(f\"Can't read an image: {image_name}\"))\n",
    "            continue\n",
    "        img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "\n",
    "        bboxes, classes, segmentations, scores = Segmentator.detect(img)\n",
    "\n",
    "\n",
    "        # for bbox, class_id, seg, score in zip(bboxes, classes, segmentations, scores):\n",
    "        #     (x, y, x2, y2) = bbox\n",
    "        #\n",
    "        #     cv2.rectangle(img, (x, y), (x2, y2), (255, 0, 0), 2)\n",
    "        #     cv2.polylines(img, [seg], True, (0, 0, 255), 4)\n",
    "        #     edges = cv2.putText(img, str(class_id), (x, y - 10), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "        #\n",
    "        #     image_name_pieces = image_name.split(\".\")\n",
    "        #     image_name = image_name_pieces[0] + \"_processed\" + \".\" + image_name_pieces[-1]\n",
    "        #     cv2.imwrite(end_path + \"/\" + image_name, edges)\n",
    "        # continue\n",
    "\n",
    "\n",
    "        for item, object_class in enumerate(classes):\n",
    "            if object_class not in classes_ids:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "        points = np.array(segmentations[item])\n",
    "\n",
    "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        cv2.drawContours(mask, [points], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "        img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        if transform_to_drawings:\n",
    "\n",
    "            blurred_image = cv2.GaussianBlur(img.copy(),(5,5),0)\n",
    "\n",
    "            img = cv2.Canny(blurred_image, 100, 160)\n",
    "\n",
    "        cv2.imwrite(end_path + \"/\" + image_name, img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:54:09.966849Z",
     "end_time": "2023-07-10T11:54:09.977248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "WHOLE_DATA_PATH = \"../output\"\n",
    "RESULT_PATH = \"../extracted_cars\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T11:54:09.983254Z",
     "end_time": "2023-07-10T11:54:10.007999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 car, 2307.5ms\n",
      "Speed: 78.1ms preprocess, 2307.5ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2121.4ms\n",
      "Speed: 0.0ms preprocess, 2121.4ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 truck, 2211.0ms\n",
      "Speed: 31.3ms preprocess, 2211.0ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2219.8ms\n",
      "Speed: 0.0ms preprocess, 2219.8ms inference, 31.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 bus, 2121.6ms\n",
      "Speed: 15.6ms preprocess, 2121.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2038.5ms\n",
      "Speed: 0.0ms preprocess, 2038.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2040.3ms\n",
      "Speed: 0.0ms preprocess, 2040.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2065.7ms\n",
      "Speed: 15.6ms preprocess, 2065.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 3081.3ms\n",
      "Speed: 0.0ms preprocess, 3081.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2683.8ms\n",
      "Speed: 15.6ms preprocess, 2683.8ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2233.6ms\n",
      "Speed: 0.0ms preprocess, 2233.6ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 4515.0ms\n",
      "Speed: 32.0ms preprocess, 4515.0ms inference, 17.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2599.0ms\n",
      "Speed: 17.0ms preprocess, 2599.0ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2519.0ms\n",
      "Speed: 10.0ms preprocess, 2519.0ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 car, 2377.0ms\n",
      "Speed: 12.0ms preprocess, 2377.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['train', 'test']:\n",
    "    folder = WHOLE_DATA_PATH + \"/\" + dataset\n",
    "    result_folder = RESULT_PATH + \"/\" + dataset\n",
    "\n",
    "    extract_contours(folder=folder,\n",
    "                     output_dir=result_folder,\n",
    "                     Segmentator=YOLOSegmentation(model_path),\n",
    "                     transform_to_drawings=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T10:44:56.123566Z",
     "end_time": "2023-07-10T10:47:37.982765Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T10:47:37.987415Z",
     "end_time": "2023-07-10T10:47:37.987415Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "yolo_torch",
   "language": "python",
   "display_name": "yolo_torch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
