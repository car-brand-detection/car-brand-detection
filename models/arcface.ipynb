{
 "metadata": {
  "kernelspec": {
   "name": "yolo_torch",
   "language": "python",
   "display_name": "yolo_torch"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">[Pytorch] ArcFace Starter</h2>\n",
    "<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Packages and requirements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install --upgrade wandb"
   ],
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:16.964850Z",
     "iopub.execute_input": "2023-08-02T12:01:16.965455Z",
     "iopub.status.idle": "2023-08-02T12:01:43.409446Z",
     "shell.execute_reply.started": "2023-08-02T12:01:16.965421Z",
     "shell.execute_reply": "2023-08-02T12:01:43.408288Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-02T21:40:54.200529Z",
     "end_time": "2023-08-02T21:40:54.216178Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_pil_image, to_grayscale, to_tensor\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import models  # Pretrained models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:43.411929Z",
     "iopub.execute_input": "2023-08-02T12:01:43.412292Z",
     "iopub.status.idle": "2023-08-02T12:01:47.043409Z",
     "shell.execute_reply.started": "2023-08-02T12:01:43.412255Z",
     "shell.execute_reply": "2023-08-02T12:01:47.042454Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Builtin libraries\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:00:09.121318Z",
     "iopub.execute_input": "2023-08-02T14:00:09.122173Z",
     "iopub.status.idle": "2023-08-02T14:00:09.135207Z",
     "shell.execute_reply.started": "2023-08-02T14:00:09.122134Z",
     "shell.execute_reply": "2023-08-02T14:00:09.133582Z"
    },
    "trusted": true
   },
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# Classic packeges for data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# Basic PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.cuda import amp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Utils\n",
    "import joblib  # Pipelining and pickling (dump/load)\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Classic ML tools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-02T21:29:21.173631Z",
     "end_time": "2023-08-02T21:29:21.173631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Albumentations is an OS library for augmentations\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mA\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ToTensorV2\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "# Albumentations is an OS library for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Output text colorizing\n",
    "from colorama import Fore, Back, Style\n",
    "yllw_bgcolor = Back.LIGHTYELLOW_EX\n",
    "reset_bgcolor = Style.RESET_ALL\n",
    "\n",
    "\n",
    "def print_highlighted(text: str, bgcolor=yllw_bgcolor) -> None:\n",
    "    \"\"\"\n",
    "    Function to print a text with colored background.\n",
    "\n",
    "    \"\"\"\n",
    "    print(bgcolor + text + reset_bgcolor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-02T21:28:16.655286Z",
     "end_time": "2023-08-02T21:28:16.689368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:49.804667Z",
     "iopub.execute_input": "2023-08-02T12:01:49.804983Z",
     "iopub.status.idle": "2023-08-02T12:01:50.111130Z",
     "shell.execute_reply.started": "2023-08-02T12:01:49.804945Z",
     "shell.execute_reply": "2023-08-02T12:01:50.110126Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-02T21:35:34.140245Z",
     "end_time": "2023-08-02T21:35:37.223544Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\possessor/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login() # We login via pop-up,\n",
    "# wandb.login(key=api_key)  # but you can also login manually with function args"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-02T21:35:37.223544Z",
     "end_time": "2023-08-02T21:36:00.392597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 2306,\n",
    "    \"epochs\": 40,\n",
    "    \"img_size\": 256,  # Depends on pretrained model used\n",
    "    \"model_name\": \"efficientnet_b0\",\n",
    "    # \"num_classes\": 166,\n",
    "    \"embedding_size\": 512,  # Embedding output size\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    # \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-8,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\n",
    "    # ArcFace Hyperparameters\n",
    "    \"s\": 30.0,\n",
    "    \"m\": 0.50,\n",
    "    \"ls_eps\": 0.0,\n",
    "    \"easy_margin\": False\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:12:50.463084Z",
     "iopub.execute_input": "2023-08-02T14:12:50.463509Z",
     "iopub.status.idle": "2023-08-02T14:12:50.472885Z",
     "shell.execute_reply.started": "2023-08-02T14:12:50.463471Z",
     "shell.execute_reply": "2023-08-02T14:12:50.471826Z"
    },
    "trusted": true
   },
   "execution_count": 119,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Seed for Reproducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(seed=CONFIG['seed'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.147165Z",
     "iopub.execute_input": "2023-08-02T12:01:50.147973Z",
     "iopub.status.idle": "2023-08-02T12:01:50.160210Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.147843Z",
     "shell.execute_reply": "2023-08-02T12:01:50.159274Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "REPO = 'car-brands/'  # dataset name on Kaggle\n",
    "ROOT_DIR = '/kaggle/input/' + REPO\n",
    "TRAIN_DIR = ROOT_DIR + '/images/train/'\n",
    "TEST_DIR = ROOT_DIR + '/images/test/'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.161456Z",
     "iopub.execute_input": "2023-08-02T12:01:50.162144Z",
     "iopub.status.idle": "2023-08-02T12:01:50.167369Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.162112Z",
     "shell.execute_reply": "2023-08-02T12:01:50.166382Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_train_file_path(file_id, dir=TRAIN_DIR):\n",
    "    return f\"{dir}/{file_id}.jpg\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.168631Z",
     "iopub.execute_input": "2023-08-02T12:01:50.169644Z",
     "iopub.status.idle": "2023-08-02T12:01:50.176602Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.169612Z",
     "shell.execute_reply": "2023-08-02T12:01:50.175543Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(f\"{ROOT_DIR}/train_labels.csv\")\n",
    "df['file_path'] = df['id'].apply(get_train_file_path)\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.178367Z",
     "iopub.execute_input": "2023-08-02T12:01:50.178874Z",
     "iopub.status.idle": "2023-08-02T12:01:50.215443Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.178843Z",
     "shell.execute_reply": "2023-08-02T12:01:50.214563Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id          label                                      file_path\n0   1  Suzuki_Escudo  /kaggle/input/car-brands//images/train//1.jpg\n1   2  Suzuki_Escudo  /kaggle/input/car-brands//images/train//2.jpg\n2   3  Suzuki_Escudo  /kaggle/input/car-brands//images/train//3.jpg\n3   4  Suzuki_Escudo  /kaggle/input/car-brands//images/train//4.jpg\n4   5  Suzuki_Escudo  /kaggle/input/car-brands//images/train//5.jpg",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Suzuki_Escudo</td>\n      <td>/kaggle/input/car-brands//images/train//1.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Suzuki_Escudo</td>\n      <td>/kaggle/input/car-brands//images/train//2.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Suzuki_Escudo</td>\n      <td>/kaggle/input/car-brands//images/train//3.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Suzuki_Escudo</td>\n      <td>/kaggle/input/car-brands//images/train//4.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Suzuki_Escudo</td>\n      <td>/kaggle/input/car-brands//images/train//5.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "encoder = LabelEncoder()\n",
    "df['label'] = encoder.fit_transform(df['label'])\n",
    "\n",
    "with open(\"le.pkl\", \"wb\") as fp:\n",
    "    joblib.dump(encoder, fp)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.219268Z",
     "iopub.execute_input": "2023-08-02T12:01:50.219552Z",
     "iopub.status.idle": "2023-08-02T12:01:50.227966Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.219530Z",
     "shell.execute_reply": "2023-08-02T12:01:50.226694Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Folds</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.label)):\n",
    "      df.loc[val_ , \"kfold\"] = fold"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.229712Z",
     "iopub.execute_input": "2023-08-02T12:01:50.230235Z",
     "iopub.status.idle": "2023-08-02T12:01:50.247835Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.230201Z",
     "shell.execute_reply": "2023-08-02T12:01:50.247034Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Dataset Class</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class HappyWhaleDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_names[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': img,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.250296Z",
     "iopub.execute_input": "2023-08-02T12:01:50.250895Z",
     "iopub.status.idle": "2023-08-02T12:01:50.258781Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.250864Z",
     "shell.execute_reply": "2023-08-02T12:01:50.257794Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.262258Z",
     "iopub.execute_input": "2023-08-02T12:01:50.262532Z",
     "iopub.status.idle": "2023-08-02T12:01:50.273232Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.262510Z",
     "shell.execute_reply": "2023-08-02T12:01:50.272169Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">GeM Pooling</h1></span>\n",
    "\n",
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://amaarora.github.io/2020/08/30/gempool.html\">GeM Pooling Explained</a></span>\n",
    "\n",
    "![](https://i.imgur.com/thTgYWG.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.275462Z",
     "iopub.execute_input": "2023-08-02T12:01:50.276035Z",
     "iopub.status.idle": "2023-08-02T12:01:50.285391Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.275997Z",
     "shell.execute_reply": "2023-08-02T12:01:50.284304Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">ArcFace</h1></span>\n",
    "\n",
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\">Landmark2019-1st-and-3rd-Place-Solution</a></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, \n",
    "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device=CONFIG['device'])\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.287114Z",
     "iopub.execute_input": "2023-08-02T12:01:50.287815Z",
     "iopub.status.idle": "2023-08-02T12:01:50.302603Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.287782Z",
     "shell.execute_reply": "2023-08-02T12:01:50.301639Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_model(model_name='resnet18', from_path=None, pretrained=False, freeze_layers=0.5, get_embeddings=False) -> torch.nn.Module:\n",
    "    got_model = False\n",
    "    if from_path:\n",
    "        try:\n",
    "            model = torch.load(model_path)\n",
    "            got_model = True\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    if not got_model:\n",
    "        model = getattr(models, model_name) # We use builtin function\n",
    "        model = model(\n",
    "        weights=('DEFAULT' if pretrained else None)\n",
    "        )\n",
    "\n",
    "    if freeze_layers:\n",
    "        params = list(model.parameters())\n",
    "    for param in params[:int(len(params)*freeze_layers)]:\n",
    "        # Freeze some layers\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if get_embeddings:\n",
    "        # That means remove classifyer (last layer):\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:01:50.304159Z",
     "iopub.execute_input": "2023-08-02T12:01:50.304698Z",
     "iopub.status.idle": "2023-08-02T12:01:50.315505Z",
     "shell.execute_reply.started": "2023-08-02T12:01:50.304619Z",
     "shell.execute_reply": "2023-08-02T12:01:50.314287Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Model</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "list(model.children())[-2].classifier"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:45:37.646600Z",
     "iopub.execute_input": "2023-08-02T14:45:37.646964Z",
     "iopub.status.idle": "2023-08-02T14:45:37.705025Z",
     "shell.execute_reply.started": "2023-08-02T14:45:37.646936Z",
     "shell.execute_reply": "2023-08-02T14:45:37.702278Z"
    },
    "trusted": true
   },
   "execution_count": 134,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[134], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchildren\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassifier\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'classifier'"
     ],
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'classifier'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class HappyWhaleModel(nn.Module):\n",
    "    def __init__(self, model, embedding_size, pretrained=True):\n",
    "        super(HappyWhaleModel, self).__init__()\n",
    "#         self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.model = model\n",
    "        in_features = 512\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=False),\n",
    "            nn.Linear(in_features=model.fc.out_features,\n",
    "                      out_features=NUM_CLASSES, bias=True)\n",
    "        )\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.embedding = nn.Linear(in_features, embedding_size)\n",
    "        self.fc = ArcMarginProduct(embedding_size, \n",
    "                                   CONFIG[\"num_classes\"],\n",
    "                                   s=CONFIG[\"s\"], \n",
    "                                   m=CONFIG[\"m\"], \n",
    "                                   easy_margin=CONFIG[\"ls_eps\"], \n",
    "                                   ls_eps=CONFIG[\"ls_eps\"])\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        embedding = self.embedding(pooled_features)\n",
    "        output = self.fc(embedding, labels)\n",
    "        return output\n",
    "    \n",
    "    def extract(self, images):\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        embedding = self.embedding(pooled_features)\n",
    "        return embedding"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:08:45.864193Z",
     "iopub.execute_input": "2023-08-02T12:08:45.864797Z",
     "iopub.status.idle": "2023-08-02T12:08:45.881684Z",
     "shell.execute_reply.started": "2023-08-02T12:08:45.864741Z",
     "shell.execute_reply": "2023-08-02T12:08:45.880689Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "    \n",
    "# model = HappyWhaleModel(CONFIG['model_name'], CONFIG['embedding_size'])\n",
    "model = get_model(model_name=CONFIG['model_name'], pretrained=True, freeze_layers=0.2, get_embeddings=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:42:00.563970Z",
     "iopub.execute_input": "2023-08-02T14:42:00.564478Z",
     "iopub.status.idle": "2023-08-02T14:42:00.761485Z",
     "shell.execute_reply.started": "2023-08-02T14:42:00.564432Z",
     "shell.execute_reply": "2023-08-02T14:42:00.760311Z"
    },
    "trusted": true
   },
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:42:57.113401Z",
     "iopub.execute_input": "2023-08-02T14:42:57.113765Z",
     "iopub.status.idle": "2023-08-02T14:42:57.121185Z",
     "shell.execute_reply.started": "2023-08-02T14:42:57.113737Z",
     "shell.execute_reply": "2023-08-02T14:42:57.119482Z"
    },
    "trusted": true
   },
   "execution_count": 128,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = HappyWhaleModel(model, CONFIG['embedding_size'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:19:06.532613Z",
     "iopub.execute_input": "2023-08-02T14:19:06.532997Z",
     "iopub.status.idle": "2023-08-02T14:19:06.545260Z",
     "shell.execute_reply.started": "2023-08-02T14:19:06.532967Z",
     "shell.execute_reply": "2023-08-02T14:19:06.544157Z"
    },
    "trusted": true
   },
   "execution_count": 122,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:19:13.644017Z",
     "iopub.execute_input": "2023-08-02T14:19:13.644419Z",
     "iopub.status.idle": "2023-08-02T14:19:13.673655Z",
     "shell.execute_reply.started": "2023-08-02T14:19:13.644388Z",
     "shell.execute_reply": "2023-08-02T14:19:13.672616Z"
    },
    "trusted": true
   },
   "execution_count": 123,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.fc"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:42:21.506718Z",
     "iopub.execute_input": "2023-08-02T14:42:21.507093Z",
     "iopub.status.idle": "2023-08-02T14:42:21.561833Z",
     "shell.execute_reply.started": "2023-08-02T14:42:21.507064Z",
     "shell.execute_reply": "2023-08-02T14:42:21.560531Z"
    },
    "trusted": true
   },
   "execution_count": 127,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[127], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'fc'"
     ],
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'fc'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, NUM_CLASSES)\n",
    "except AttributeError:\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=False),\n",
    "        nn.Linear(in_features=model.fc.out_features,\n",
    "                  out_features=NUM_CLASSES, bias=True)\n",
    "    )"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def criterion(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T12:08:47.013676Z",
     "iopub.execute_input": "2023-08-02T12:08:47.013997Z",
     "iopub.status.idle": "2023-08-02T12:08:47.018676Z",
     "shell.execute_reply.started": "2023-08-02T12:08:47.013971Z",
     "shell.execute_reply": "2023-08-02T12:08:47.017723Z"
    },
    "trusted": true
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0.0\n",
    "    train_total = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        labels = data['label'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        outputs = model(images, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "        accuracy = train_correct / train_total\n",
    "        \n",
    "        \n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, accuracy"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:17:25.966882Z",
     "iopub.execute_input": "2023-08-02T13:17:25.967290Z",
     "iopub.status.idle": "2023-08-02T13:17:25.980706Z",
     "shell.execute_reply.started": "2023-08-02T13:17:25.967228Z",
     "shell.execute_reply": "2023-08-02T13:17:25.979745Z"
    },
    "trusted": true
   },
   "execution_count": 101,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "@torch.inference_mode()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    val_correct = 0.0\n",
    "    val_total = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        labels = data['label'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        outputs = model(images, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "        val_total += labels.size(0)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        accuracy = val_correct / val_total\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, accuracy"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:17:26.268722Z",
     "iopub.execute_input": "2023-08-02T13:17:26.269543Z",
     "iopub.status.idle": "2023-08-02T13:17:26.279454Z",
     "shell.execute_reply.started": "2023-08-02T13:17:26.269506Z",
     "shell.execute_reply": "2023-08-02T13:17:26.277403Z"
    },
    "trusted": true
   },
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_stats(\n",
    "        train_loss: list[float],\n",
    "        valid_loss: list[float],\n",
    "        train_accuracy: list[float],\n",
    "        valid_accuracy: list[float],\n",
    "        title: str = None\n",
    "):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' accuracy')\n",
    "\n",
    "    plt.plot(train_accuracy, label='Train accuracy')\n",
    "    plt.plot(valid_accuracy, label='Valid accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:17:26.436114Z",
     "iopub.execute_input": "2023-08-02T13:17:26.437359Z",
     "iopub.status.idle": "2023-08-02T13:17:26.445079Z",
     "shell.execute_reply.started": "2023-08-02T13:17:26.437287Z",
     "shell.execute_reply": "2023-08-02T13:17:26.444055Z"
    },
    "trusted": true
   },
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h1></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_accuracy = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, val_accuracy = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train Accuracy'].append(train_accuracy)\n",
    "        history['Valid Accuracy'].append(val_accuracy)\n",
    "        \n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "        wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "        wandb.log({\"Train Accuracy\": train_accuracy})\n",
    "        wandb.log({\"Valid Accuracy\": val_accuracy})\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plot_stats(\n",
    "        history['Train Loss'],\n",
    "        history['Valid Loss'],\n",
    "        history['Train Accuracy'],\n",
    "        history['Valid Accuracy'],\n",
    "        title = 'resnet18 Model'\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:46:45.901522Z",
     "iopub.execute_input": "2023-08-02T13:46:45.901916Z",
     "iopub.status.idle": "2023-08-02T13:46:45.919267Z",
     "shell.execute_reply.started": "2023-08-02T13:46:45.901878Z",
     "shell.execute_reply": "2023-08-02T13:46:45.918132Z"
    },
    "trusted": true
   },
   "execution_count": 111,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:46:49.245523Z",
     "iopub.execute_input": "2023-08-02T13:46:49.246497Z",
     "iopub.status.idle": "2023-08-02T13:46:49.254480Z",
     "shell.execute_reply.started": "2023-08-02T13:46:49.246462Z",
     "shell.execute_reply": "2023-08-02T13:46:49.252995Z"
    },
    "trusted": true
   },
   "execution_count": 112,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_loaders(df, fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"])\n",
    "    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:46:51.478904Z",
     "iopub.execute_input": "2023-08-02T13:46:51.479263Z",
     "iopub.status.idle": "2023-08-02T13:46:51.488118Z",
     "shell.execute_reply.started": "2023-08-02T13:46:51.479233Z",
     "shell.execute_reply": "2023-08-02T13:46:51.486943Z"
    },
    "trusted": true
   },
   "execution_count": 113,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Prepare Dataloaders</span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader, valid_loader = prepare_loaders(df, fold=0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:46:51.873071Z",
     "iopub.execute_input": "2023-08-02T13:46:51.873408Z",
     "iopub.status.idle": "2023-08-02T13:46:51.883201Z",
     "shell.execute_reply.started": "2023-08-02T13:46:51.873381Z",
     "shell.execute_reply": "2023-08-02T13:46:51.881976Z"
    },
    "trusted": true
   },
   "execution_count": 114,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Define Optimizer and Scheduler</span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                       weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = fetch_scheduler(optimizer)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:46:53.025312Z",
     "iopub.execute_input": "2023-08-02T13:46:53.025686Z",
     "iopub.status.idle": "2023-08-02T13:46:53.033674Z",
     "shell.execute_reply.started": "2023-08-02T13:46:53.025658Z",
     "shell.execute_reply": "2023-08-02T13:46:53.031821Z"
    },
    "trusted": true
   },
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "run = wandb.init(project='HappyWhale', \n",
    "                 config=CONFIG,\n",
    "                 job_type='Train',\n",
    "                 tags=['arcface', 'gem-pooling', 'effnet-b0-ns', '448'],\n",
    "                 anonymous='must')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:17:29.326170Z",
     "iopub.execute_input": "2023-08-02T13:17:29.326547Z",
     "iopub.status.idle": "2023-08-02T13:18:05.366184Z",
     "shell.execute_reply.started": "2023-08-02T13:17:29.326517Z",
     "shell.execute_reply": "2023-08-02T13:18:05.365316Z"
    },
    "trusted": true
   },
   "execution_count": 109,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:cxf7ag8l) before initializing another..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.033 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.032277",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8562dc56585846afa4b86f59b2c670a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">genial-surf-6</strong> at: <a href='https://wandb.ai/anony-moose-304097416530182356/HappyWhale/runs/cxf7ag8l?apiKey=ce3616ae2994b5f009669d2516e94272126cf181' target=\"_blank\">https://wandb.ai/anony-moose-304097416530182356/HappyWhale/runs/cxf7ag8l?apiKey=ce3616ae2994b5f009669d2516e94272126cf181</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230802_131549-cxf7ag8l/logs</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:cxf7ag8l). Initializing new run:<br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.8"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20230802_131729-hreiwxwb</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/anony-moose-304097416530182356/HappyWhale/runs/hreiwxwb?apiKey=ce3616ae2994b5f009669d2516e94272126cf181' target=\"_blank\">lucky-sponge-7</a></strong> to <a href='https://wandb.ai/anony-moose-304097416530182356/HappyWhale?apiKey=ce3616ae2994b5f009669d2516e94272126cf181' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/anony-moose-304097416530182356/HappyWhale?apiKey=ce3616ae2994b5f009669d2516e94272126cf181' target=\"_blank\">https://wandb.ai/anony-moose-304097416530182356/HappyWhale?apiKey=ce3616ae2994b5f009669d2516e94272126cf181</a>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/anony-moose-304097416530182356/HappyWhale/runs/hreiwxwb?apiKey=ce3616ae2994b5f009669d2516e94272126cf181' target=\"_blank\">https://wandb.ai/anony-moose-304097416530182356/HappyWhale/runs/hreiwxwb?apiKey=ce3616ae2994b5f009669d2516e94272126cf181</a>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Do NOT share these links with anyone. They can be used to claim your runs."
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model, history = run_training(model, optimizer, scheduler,\n",
    "                              device=CONFIG['device'],\n",
    "                              num_epochs=CONFIG['epochs'],\n",
    "#                               num_epochs=2\n",
    "                             )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T14:20:01.542783Z",
     "iopub.execute_input": "2023-08-02T14:20:01.543142Z",
     "iopub.status.idle": "2023-08-02T14:20:03.046265Z",
     "shell.execute_reply.started": "2023-08-02T14:20:01.543112Z",
     "shell.execute_reply": "2023-08-02T14:20:03.043046Z"
    },
    "trusted": true
   },
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "text": "[INFO] Using GPU: Tesla P100-PCIE-16GB\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "  0%|          | 0/141 [00:00<?, ?it/s]\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[124], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model, history \u001B[38;5;241m=\u001B[39m \u001B[43mrun_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCONFIG\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCONFIG\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mepochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;43;03m#                               num_epochs=2\u001B[39;49;00m\n\u001B[1;32m      5\u001B[0m \u001B[43m                             \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[111], line 15\u001B[0m, in \u001B[0;36mrun_training\u001B[0;34m(model, optimizer, scheduler, device, num_epochs)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m): \n\u001B[1;32m     14\u001B[0m     gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[0;32m---> 15\u001B[0m     train_epoch_loss, train_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCONFIG\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     val_epoch_loss, val_accuracy \u001B[38;5;241m=\u001B[39m valid_one_epoch(model, valid_loader, device\u001B[38;5;241m=\u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m], \n\u001B[1;32m     20\u001B[0m                                      epoch\u001B[38;5;241m=\u001B[39mepoch)\n\u001B[1;32m     22\u001B[0m     history[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain Loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(train_epoch_loss)\n",
      "Cell \u001B[0;32mIn[101], line 16\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001B[0m\n\u001B[1;32m     12\u001B[0m labels \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[1;32m     14\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     18\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m CONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_accumulate\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[55], line 21\u001B[0m, in \u001B[0;36mHappyWhaleModel.forward\u001B[0;34m(self, images, labels)\u001B[0m\n\u001B[1;32m     19\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(images)\n\u001B[1;32m     20\u001B[0m pooled_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling(features)\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 21\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpooled_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(embedding, labels)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (32x1280 and 512x512)"
     ],
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x1280 and 512x512)",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "run.finish()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-02T13:45:32.994928Z",
     "iopub.status.idle": "2023-08-02T13:45:32.996064Z",
     "shell.execute_reply.started": "2023-08-02T13:45:32.995821Z",
     "shell.execute_reply": "2023-08-02T13:45:32.995845Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualizations</h1>\n",
    "\n",
    "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https://wandb.ai/dchanda/HappyWhale/runs/3l3k91tm\">View the Complete Dashboard Here </a></span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://i.imgur.com/3Cc8KBH.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)"
   ],
   "metadata": {}
  }
 ]
}
