{
 "metadata": {
  "kernelspec": {
   "name": "yolo_torch",
   "language": "python",
   "display_name": "yolo_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3960.405937,
   "end_time": "2023-08-14T17:29:54.480893",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-14T16:23:54.074956",
   "version": "2.4.0"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pairwise Binary classification with Deep Learning"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.028248,
     "end_time": "2023-08-14T16:24:04.236116",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.207868",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we will train Multilayer Perceptron Neural Network to detect whether two images are from same class (car brand) or not. To train Perceptron, we will use image embeddings got from trained CNN model (SOTA models such as MobileNet)."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.0269,
     "end_time": "2023-08-14T16:24:04.291517",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.264617",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up"
   ],
   "metadata": {
    "id": "DRrvM2BPUG3T",
    "papermill": {
     "duration": 0.02718,
     "end_time": "2023-08-14T16:24:04.346391",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.319211",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Packages and requirements"
   ],
   "metadata": {
    "id": "G-cGfk5CTFDT",
    "papermill": {
     "duration": 0.026993,
     "end_time": "2023-08-14T16:24:04.400603",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.373610",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Major builtin libraries\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import typing as t\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:37.943401Z",
     "end_time": "2023-08-19T11:34:38.779292Z"
    },
    "id": "YJ1bPQE1TFDW",
    "papermill": {
     "duration": 0.044843,
     "end_time": "2023-08-14T16:24:04.472823",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.427980",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:15:57.323559Z",
     "iopub.execute_input": "2023-08-17T07:15:57.323917Z",
     "iopub.status.idle": "2023-08-17T07:15:57.330822Z",
     "shell.execute_reply.started": "2023-08-17T07:15:57.323886Z",
     "shell.execute_reply": "2023-08-17T07:15:57.328160Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings  # If you want to disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:37.951141Z",
     "end_time": "2023-08-19T11:34:38.779292Z"
    },
    "id": "BwyVeWsUTFDX",
    "papermill": {
     "duration": 0.035469,
     "end_time": "2023-08-14T16:24:04.598152",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.562683",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:15:57.351506Z",
     "iopub.execute_input": "2023-08-17T07:15:57.352204Z",
     "iopub.status.idle": "2023-08-17T07:15:57.359600Z",
     "shell.execute_reply.started": "2023-08-17T07:15:57.352170Z",
     "shell.execute_reply": "2023-08-17T07:15:57.358625Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Classic packages for data manipulation and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:37.951141Z",
     "end_time": "2023-08-19T11:34:40.013139Z"
    },
    "id": "AGRBRJORTFDX",
    "papermill": {
     "duration": 0.035178,
     "end_time": "2023-08-14T16:24:04.660718",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.625540",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:15:57.363018Z",
     "iopub.execute_input": "2023-08-17T07:15:57.363728Z",
     "iopub.status.idle": "2023-08-17T07:15:57.522644Z",
     "shell.execute_reply.started": "2023-08-17T07:15:57.363695Z",
     "shell.execute_reply": "2023-08-17T07:15:57.521747Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Basic PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # Optimization algorithms and dynamic learning rate adjusting\n",
    "import torch.nn.functional as F\n",
    "# from torch.nn.modules.loss import _Loss  # For writing a custom Loss function\n",
    "from torch.utils.data import DataLoader, Dataset  # For custom data presentation"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:39.999141Z",
     "end_time": "2023-08-19T11:34:44.056613Z"
    },
    "id": "FXSN-XzxTFDX",
    "papermill": {
     "duration": 3.82041,
     "end_time": "2023-08-14T16:24:08.508190",
     "exception": false,
     "start_time": "2023-08-14T16:24:04.687780",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:15:57.524533Z",
     "iopub.execute_input": "2023-08-17T07:15:57.524842Z",
     "iopub.status.idle": "2023-08-17T07:15:59.036652Z",
     "shell.execute_reply.started": "2023-08-17T07:15:57.524811Z",
     "shell.execute_reply": "2023-08-17T07:15:59.035663Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Utils\n",
    "import joblib  # Pipelining, pickling (dump/load), parallel processing\n",
    "from tqdm import tqdm  # Progress bar for training process\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# Classic ML tools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold  # Cross-Validation"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:44.056613Z",
     "end_time": "2023-08-19T11:34:45.397334Z"
    },
    "id": "7QjRLiOzTFDY",
    "papermill": {
     "duration": 0.980731,
     "end_time": "2023-08-14T16:24:09.517905",
     "exception": false,
     "start_time": "2023-08-14T16:24:08.537174",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:15:59.038198Z",
     "iopub.execute_input": "2023-08-17T07:15:59.039259Z",
     "iopub.status.idle": "2023-08-17T07:15:59.645345Z",
     "shell.execute_reply.started": "2023-08-17T07:15:59.039220Z",
     "shell.execute_reply": "2023-08-17T07:15:59.644319Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ML Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from torchmetrics.classification import MulticlassF1Score, F1Score # F1 metric for multiclass"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:45.397334Z",
     "end_time": "2023-08-19T11:34:46.754810Z"
    },
    "id": "BuY4s3bsTFDZ",
    "papermill": {
     "duration": 10.177643,
     "end_time": "2023-08-14T16:24:20.158465",
     "exception": false,
     "start_time": "2023-08-14T16:24:09.980822",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:15:59.655265Z",
     "iopub.execute_input": "2023-08-17T07:15:59.655975Z",
     "iopub.status.idle": "2023-08-17T07:16:09.540861Z",
     "shell.execute_reply.started": "2023-08-17T07:15:59.655941Z",
     "shell.execute_reply": "2023-08-17T07:16:09.539912Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Torch Computer Vision tools for images processing\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_pil_image, to_grayscale, to_tensor\n",
    "from torchvision import models  # Pretrained models"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:46.761884Z",
     "end_time": "2023-08-19T11:34:46.762397Z"
    },
    "id": "FEKtt6X5TFDZ",
    "papermill": {
     "duration": 0.03877,
     "end_time": "2023-08-14T16:24:20.224798",
     "exception": false,
     "start_time": "2023-08-14T16:24:20.186028",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:09.542028Z",
     "iopub.execute_input": "2023-08-17T07:16:09.542369Z",
     "iopub.status.idle": "2023-08-17T07:16:09.549300Z",
     "shell.execute_reply.started": "2023-08-17T07:16:09.542337Z",
     "shell.execute_reply": "2023-08-17T07:16:09.548129Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Albumentations is an OS library for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# import torchvision.transforms as T  # We can use torch augmentations instead"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:46.762397Z",
     "end_time": "2023-08-19T11:34:47.281452Z"
    },
    "id": "90C8yH1dTFDa",
    "papermill": {
     "duration": 0.930793,
     "end_time": "2023-08-14T16:24:21.182870",
     "exception": false,
     "start_time": "2023-08-14T16:24:20.252077",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:09.551106Z",
     "iopub.execute_input": "2023-08-17T07:16:09.551869Z",
     "iopub.status.idle": "2023-08-17T07:16:10.486598Z",
     "shell.execute_reply.started": "2023-08-17T07:16:09.551830Z",
     "shell.execute_reply": "2023-08-17T07:16:10.485516Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Output text colorizing\n",
    "from colorama import Back, Style\n",
    "\n",
    "def print_highlighted(text: str, bgcolor=Back.YELLOW) -> None:\n",
    "    \"\"\"\n",
    "    Function to print a text with colored background.\n",
    "    \"\"\"\n",
    "    print(bgcolor + text + Style.RESET_ALL)"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:47.281452Z",
     "end_time": "2023-08-19T11:34:47.290677Z"
    },
    "collapsed": false,
    "id": "pF1AWOXTTFDa",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037099,
     "end_time": "2023-08-14T16:24:21.300878",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.263779",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:10.487905Z",
     "iopub.execute_input": "2023-08-17T07:16:10.489329Z",
     "iopub.status.idle": "2023-08-17T07:16:10.496277Z",
     "shell.execute_reply.started": "2023-08-17T07:16:10.489293Z",
     "shell.execute_reply": "2023-08-17T07:16:10.494608Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb # MLOps platform to simplify and speed up the process of building ML models"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:47.290677Z",
     "end_time": "2023-08-19T11:34:48.498710Z"
    },
    "collapsed": false,
    "id": "WHnMHaX_TFDb",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034479,
     "end_time": "2023-08-14T16:24:21.363117",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.328638",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:10.498039Z",
     "iopub.execute_input": "2023-08-17T07:16:10.498837Z",
     "iopub.status.idle": "2023-08-17T07:16:10.509859Z",
     "shell.execute_reply.started": "2023-08-17T07:16:10.498799Z",
     "shell.execute_reply": "2023-08-17T07:16:10.508871Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb.login() # We log in via pop-up,\n",
    "# wandb.login(key=api_key)  # but you can also log in manually with function args"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:48.498710Z",
     "end_time": "2023-08-19T11:34:54.442700Z"
    },
    "collapsed": false,
    "id": "1zarBgpbTFDb",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034968,
     "end_time": "2023-08-14T16:24:21.425112",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.390144",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:10.515134Z",
     "iopub.execute_input": "2023-08-17T07:16:10.515417Z",
     "iopub.status.idle": "2023-08-17T07:16:21.325214Z",
     "shell.execute_reply.started": "2023-08-17T07:16:10.515392Z",
     "shell.execute_reply": "2023-08-17T07:16:21.324243Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mremainedmind\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration"
   ],
   "metadata": {
    "id": "YuquAHEkTFDb",
    "papermill": {
     "duration": 0.026802,
     "end_time": "2023-08-14T16:24:21.479509",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.452707",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 2306,\n",
    "    # \"epochs\": 20,\n",
    "    \"image_dimension\": 256,  # Depends on pretrained model used\n",
    "    \"model_name\": \"SiamesePerceptron\",  # Pretrained model we will use\n",
    "    \"embedding_size\": 512,  # Embedding output size\n",
    "    \"train_batch_size\": 200,\n",
    "    \"val_batch_size\": 400,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"min_lr\": 1e-8,\n",
    "    \"min_loss_delta\": 1e-7, # To stop training on plateau\n",
    "    \"weight_decay\": 1e-7,\n",
    "\n",
    "}"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:54.442700Z",
     "end_time": "2023-08-19T11:34:54.451213Z"
    },
    "id": "JC-SbC9zTFDb",
    "papermill": {
     "duration": 0.036674,
     "end_time": "2023-08-14T16:24:21.543459",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.506785",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:21.326556Z",
     "iopub.execute_input": "2023-08-17T07:16:21.327582Z",
     "iopub.status.idle": "2023-08-17T07:16:21.333528Z",
     "shell.execute_reply.started": "2023-08-17T07:16:21.327545Z",
     "shell.execute_reply": "2023-08-17T07:16:21.332534Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb_run = wandb.init(project=\"cars-classification-project\", config=CONFIG)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:54.451213Z",
     "end_time": "2023-08-19T11:34:55.946628Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:21.334769Z",
     "iopub.execute_input": "2023-08-17T07:16:21.335578Z",
     "iopub.status.idle": "2023-08-17T07:16:53.875522Z",
     "shell.execute_reply.started": "2023-08-17T07:16:21.335544Z",
     "shell.execute_reply": "2023-08-17T07:16:53.874496Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.8"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\possessor\\Documents\\ESSE\\IT\\ML\\CV\\Statanly_Internship\\Projects\\car-brand-detection\\models\\wandb\\run-20230819_113454-hqsygcdr</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/remainedmind/cars-classification-project/runs/hqsygcdr' target=\"_blank\">peachy-capybara-11</a></strong> to <a href='https://wandb.ai/remainedmind/cars-classification-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/remainedmind/cars-classification-project' target=\"_blank\">https://wandb.ai/remainedmind/cars-classification-project</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/remainedmind/cars-classification-project/runs/hqsygcdr' target=\"_blank\">https://wandb.ai/remainedmind/cars-classification-project/runs/hqsygcdr</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = wandb.config\n",
    "del CONFIG"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:55.946628Z",
     "end_time": "2023-08-19T11:34:55.975943Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:53.877070Z",
     "iopub.execute_input": "2023-08-17T07:16:53.877403Z",
     "iopub.status.idle": "2023-08-17T07:16:53.883235Z",
     "shell.execute_reply.started": "2023-08-17T07:16:53.877371Z",
     "shell.execute_reply": "2023-08-17T07:16:53.882350Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set Seed for Reproducibility"
   ],
   "metadata": {
    "id": "kotMeU-OTFDc",
    "papermill": {
     "duration": 0.027693,
     "end_time": "2023-08-14T16:24:21.791364",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.763671",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False  # When False, this option makes CUDA reproducible, BUT the performance might suffer\n",
    "\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(seed=config.seed)"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:55.955155Z",
     "end_time": "2023-08-19T11:34:55.975943Z"
    },
    "id": "RDIHP75uTFDc",
    "papermill": {
     "duration": 0.045937,
     "end_time": "2023-08-14T16:24:21.869710",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.823773",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:53.885297Z",
     "iopub.execute_input": "2023-08-17T07:16:53.886593Z",
     "iopub.status.idle": "2023-08-17T07:16:53.898928Z",
     "shell.execute_reply.started": "2023-08-17T07:16:53.886559Z",
     "shell.execute_reply": "2023-08-17T07:16:53.897911Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "id": "UoHh0H1FVHnT",
    "papermill": {
     "duration": 0.027822,
     "end_time": "2023-08-14T16:24:21.925361",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.897539",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For our MLP we will use image embeddings - output from CNN models. We already got this data before, so we just load it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set data location"
   ],
   "metadata": {
    "id": "Qst3Y-s4VKTk",
    "papermill": {
     "duration": 0.042797,
     "end_time": "2023-08-14T16:24:22.001996",
     "exception": false,
     "start_time": "2023-08-14T16:24:21.959199",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# config.repo = 'car-brands/'  # dataset name on Kaggle\n",
    "config.repo = 'data/'  # dataset name on local device\n",
    "# config.repo = 'car_brand_detection/'  # Google Collab\n",
    "\n",
    "# config.root = '/kaggle/input/' + config.repo\n",
    "# config.root = 'drive/MyDrive/' + config.repo\n",
    "config.root = '../'  + config.repo\n",
    "\n",
    "config.data_path = config.root + 'embeddings_and_labels.csv'\n",
    "config.test_images_path = config.root + 'images/test'\n",
    "config.test_labels = config.root + 'test_labels.csv'\n",
    "\n",
    "config.mlp_model_path = 'saved_instances/SiamesePerceptron.pth'\n",
    "config.save_model_to = f'{config.model_name}.pth'"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:55.975943Z",
     "end_time": "2023-08-19T11:34:56.015266Z"
    },
    "id": "QKDBLmMrTFDd",
    "papermill": {
     "duration": 0.036856,
     "end_time": "2023-08-14T16:24:22.084008",
     "exception": false,
     "start_time": "2023-08-14T16:24:22.047152",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:53.900397Z",
     "iopub.execute_input": "2023-08-17T07:16:53.900974Z",
     "iopub.status.idle": "2023-08-17T07:16:53.912188Z",
     "shell.execute_reply.started": "2023-08-17T07:16:53.900944Z",
     "shell.execute_reply": "2023-08-17T07:16:53.911297Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(config.data_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:55.988876Z",
     "end_time": "2023-08-19T11:34:58.031526Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:53.913988Z",
     "iopub.execute_input": "2023-08-17T07:16:53.914761Z",
     "iopub.status.idle": "2023-08-17T07:16:58.842205Z",
     "shell.execute_reply.started": "2023-08-17T07:16:53.914726Z",
     "shell.execute_reply": "2023-08-17T07:16:58.841235Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0 -0.001561  0.159091 -0.326709 -0.226603 -0.097365  0.204614 -0.142634   \n1  0.229466 -0.186505 -0.329016 -0.650666  0.115301  0.149208  0.065496   \n2 -0.203165  0.330612 -0.413488 -0.128357  0.013811  0.244605 -0.137738   \n3 -0.052456  0.385235 -0.423291 -0.007358  0.031012  0.242327  0.118072   \n4  0.092909  0.075529 -0.040490  0.137453  0.531280  0.219033 -0.100117   \n\n          7         8         9  ...       503       504       505       506  \\\n0  0.208764  0.469837  0.069866  ...  0.410457 -0.024682  0.178265 -0.357340   \n1  0.191487  0.428920 -0.016147  ...  0.195697  0.171068  0.037157  0.049534   \n2  0.365148  0.385303  0.318809  ...  0.413026  0.040102  0.054195 -0.251548   \n3  0.235620  0.464901  0.320997  ...  0.412529  0.015200  0.237078 -0.429586   \n4  0.161784 -0.077920 -0.265161  ... -0.024520  0.143381 -0.099898  0.137324   \n\n        507       508       509       510       511      label  \n0 -0.073279  0.190458 -0.060786  0.364546  0.824516  Acura_MDX  \n1 -0.224402  0.225593  0.180314  0.073213  0.500426  Acura_MDX  \n2 -0.020557  0.241178  0.062900  0.354683  0.591870  Acura_MDX  \n3 -0.110773  0.166453  0.079581  0.243743  0.662615  Acura_MDX  \n4  0.137523  0.217806  0.313156  0.400654  0.217053  Acura_MDX  \n\n[5 rows x 513 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>503</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.001561</td>\n      <td>0.159091</td>\n      <td>-0.326709</td>\n      <td>-0.226603</td>\n      <td>-0.097365</td>\n      <td>0.204614</td>\n      <td>-0.142634</td>\n      <td>0.208764</td>\n      <td>0.469837</td>\n      <td>0.069866</td>\n      <td>...</td>\n      <td>0.410457</td>\n      <td>-0.024682</td>\n      <td>0.178265</td>\n      <td>-0.357340</td>\n      <td>-0.073279</td>\n      <td>0.190458</td>\n      <td>-0.060786</td>\n      <td>0.364546</td>\n      <td>0.824516</td>\n      <td>Acura_MDX</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.229466</td>\n      <td>-0.186505</td>\n      <td>-0.329016</td>\n      <td>-0.650666</td>\n      <td>0.115301</td>\n      <td>0.149208</td>\n      <td>0.065496</td>\n      <td>0.191487</td>\n      <td>0.428920</td>\n      <td>-0.016147</td>\n      <td>...</td>\n      <td>0.195697</td>\n      <td>0.171068</td>\n      <td>0.037157</td>\n      <td>0.049534</td>\n      <td>-0.224402</td>\n      <td>0.225593</td>\n      <td>0.180314</td>\n      <td>0.073213</td>\n      <td>0.500426</td>\n      <td>Acura_MDX</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.203165</td>\n      <td>0.330612</td>\n      <td>-0.413488</td>\n      <td>-0.128357</td>\n      <td>0.013811</td>\n      <td>0.244605</td>\n      <td>-0.137738</td>\n      <td>0.365148</td>\n      <td>0.385303</td>\n      <td>0.318809</td>\n      <td>...</td>\n      <td>0.413026</td>\n      <td>0.040102</td>\n      <td>0.054195</td>\n      <td>-0.251548</td>\n      <td>-0.020557</td>\n      <td>0.241178</td>\n      <td>0.062900</td>\n      <td>0.354683</td>\n      <td>0.591870</td>\n      <td>Acura_MDX</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.052456</td>\n      <td>0.385235</td>\n      <td>-0.423291</td>\n      <td>-0.007358</td>\n      <td>0.031012</td>\n      <td>0.242327</td>\n      <td>0.118072</td>\n      <td>0.235620</td>\n      <td>0.464901</td>\n      <td>0.320997</td>\n      <td>...</td>\n      <td>0.412529</td>\n      <td>0.015200</td>\n      <td>0.237078</td>\n      <td>-0.429586</td>\n      <td>-0.110773</td>\n      <td>0.166453</td>\n      <td>0.079581</td>\n      <td>0.243743</td>\n      <td>0.662615</td>\n      <td>Acura_MDX</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.092909</td>\n      <td>0.075529</td>\n      <td>-0.040490</td>\n      <td>0.137453</td>\n      <td>0.531280</td>\n      <td>0.219033</td>\n      <td>-0.100117</td>\n      <td>0.161784</td>\n      <td>-0.077920</td>\n      <td>-0.265161</td>\n      <td>...</td>\n      <td>-0.024520</td>\n      <td>0.143381</td>\n      <td>-0.099898</td>\n      <td>0.137324</td>\n      <td>0.137523</td>\n      <td>0.217806</td>\n      <td>0.313156</td>\n      <td>0.400654</td>\n      <td>0.217053</td>\n      <td>Acura_MDX</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 513 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.columns[-20:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.031526Z",
     "end_time": "2023-08-19T11:34:58.042362Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.846617Z",
     "iopub.execute_input": "2023-08-17T07:16:58.848943Z",
     "iopub.status.idle": "2023-08-17T07:16:58.858952Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.848905Z",
     "shell.execute_reply": "2023-08-17T07:16:58.857820Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['493', '494', '495', '496', '497', '498', '499', '500', '501', '502',\n       '503', '504', '505', '506', '507', '508', '509', '510', '511', 'label'],\n      dtype='object')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**label** is our last column. Rest are embeddings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "embeddings_bag = df[(df.columns[:-1])]\n",
    "embeddings_bag.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.042362Z",
     "end_time": "2023-08-19T11:34:58.225446Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.860529Z",
     "iopub.execute_input": "2023-08-17T07:16:58.863661Z",
     "iopub.status.idle": "2023-08-17T07:16:58.932109Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.863622Z",
     "shell.execute_reply": "2023-08-17T07:16:58.931046Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0 -0.001561  0.159091 -0.326709 -0.226603 -0.097365  0.204614 -0.142634   \n1  0.229466 -0.186505 -0.329016 -0.650666  0.115301  0.149208  0.065496   \n\n          7         8         9  ...       502       503       504       505  \\\n0  0.208764  0.469837  0.069866  ...  0.111356  0.410457 -0.024682  0.178265   \n1  0.191487  0.428920 -0.016147  ...  0.135340  0.195697  0.171068  0.037157   \n\n        506       507       508       509       510       511  \n0 -0.357340 -0.073279  0.190458 -0.060786  0.364546  0.824516  \n1  0.049534 -0.224402  0.225593  0.180314  0.073213  0.500426  \n\n[2 rows x 512 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>502</th>\n      <th>503</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.001561</td>\n      <td>0.159091</td>\n      <td>-0.326709</td>\n      <td>-0.226603</td>\n      <td>-0.097365</td>\n      <td>0.204614</td>\n      <td>-0.142634</td>\n      <td>0.208764</td>\n      <td>0.469837</td>\n      <td>0.069866</td>\n      <td>...</td>\n      <td>0.111356</td>\n      <td>0.410457</td>\n      <td>-0.024682</td>\n      <td>0.178265</td>\n      <td>-0.357340</td>\n      <td>-0.073279</td>\n      <td>0.190458</td>\n      <td>-0.060786</td>\n      <td>0.364546</td>\n      <td>0.824516</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.229466</td>\n      <td>-0.186505</td>\n      <td>-0.329016</td>\n      <td>-0.650666</td>\n      <td>0.115301</td>\n      <td>0.149208</td>\n      <td>0.065496</td>\n      <td>0.191487</td>\n      <td>0.428920</td>\n      <td>-0.016147</td>\n      <td>...</td>\n      <td>0.135340</td>\n      <td>0.195697</td>\n      <td>0.171068</td>\n      <td>0.037157</td>\n      <td>0.049534</td>\n      <td>-0.224402</td>\n      <td>0.225593</td>\n      <td>0.180314</td>\n      <td>0.073213</td>\n      <td>0.500426</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 512 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "labels = df[df.columns[-1]]\n",
    "labels.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.118699Z",
     "end_time": "2023-08-19T11:34:58.225446Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.933583Z",
     "iopub.execute_input": "2023-08-17T07:16:58.937799Z",
     "iopub.status.idle": "2023-08-17T07:16:58.950565Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.937760Z",
     "shell.execute_reply": "2023-08-17T07:16:58.949510Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Acura_MDX\n1    Acura_MDX\nName: label, dtype: object"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "labels.unique()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.130912Z",
     "end_time": "2023-08-19T11:34:58.241100Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.955437Z",
     "iopub.execute_input": "2023-08-17T07:16:58.957825Z",
     "iopub.status.idle": "2023-08-17T07:16:58.974407Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.957788Z",
     "shell.execute_reply": "2023-08-17T07:16:58.973248Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Acura_MDX', 'Alfa Romeo_Giulietta', 'Audi_100', 'Audi_80',\n       'Audi_A1', 'Audi_A3', 'Audi_A4', 'Audi_A5', 'Audi_A6', 'Audi_A7'],\n      dtype=object)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config.num_of_classes = labels.nunique()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.975570Z",
     "iopub.execute_input": "2023-08-17T07:16:58.975874Z",
     "iopub.status.idle": "2023-08-17T07:16:58.985886Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.975842Z",
     "shell.execute_reply": "2023-08-17T07:16:58.984983Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.147080Z",
     "end_time": "2023-08-19T11:34:58.256723Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we apply One Hot Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def apply_label_encoding(labels: t.Union[pd.Series, np.array],\n",
    "                         encoder_name: os.path,\n",
    "                         action='encode',\n",
    "     ):\n",
    "    \"\"\"\n",
    "    One Hot encoding. We apply encoding by replacing the label column in dataframe.\n",
    "    As for decoding data back, we work with vector-array (as it's most likely to\n",
    "    be a prediction result)\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    if action == 'encode':\n",
    "        # We transform dataframe here. Nothing returns\n",
    "        # data = data.with_columns(pl.DataFrame(encoder.fit_transform(data[column]), schema=['label']))\n",
    "        encoder_name = f\"{encoder_name}_LEncoder.pkl\"\n",
    "        if encoder_name in os.listdir():\n",
    "            with open(encoder_name, \"rb\") as fp:\n",
    "                encoder: LabelEncoder = joblib.load(fp)\n",
    "            labels = encoder.transform(labels)\n",
    "            print_highlighted(\"Encoded with existing encoder.\")\n",
    "        else:\n",
    "            labels = encoder.fit_transform(labels)\n",
    "            with open(encoder_name, \"wb\") as fp:\n",
    "                joblib.dump(encoder, fp)\n",
    "        return labels\n",
    "    elif action == 'decode':\n",
    "        # We pass vector here. Result is a vector\n",
    "        with open(f\"{encoder_name}_LEncoder.pkl\", \"rb\") as fp:\n",
    "            encoder: LabelEncoder = joblib.load(fp)\n",
    "        return encoder.inverse_transform(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.158737Z",
     "end_time": "2023-08-19T11:34:58.256723Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.987545Z",
     "iopub.execute_input": "2023-08-17T07:16:58.988159Z",
     "iopub.status.idle": "2023-08-17T07:16:58.997030Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.988124Z",
     "shell.execute_reply": "2023-08-17T07:16:58.996053Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labels = pd.DataFrame(apply_label_encoding(labels, action='encode', encoder_name=\"embeddings_labels\"), columns=['label'])\n",
    "labels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.171373Z",
     "end_time": "2023-08-19T11:34:58.256723Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:58.998417Z",
     "iopub.execute_input": "2023-08-17T07:16:58.999152Z",
     "iopub.status.idle": "2023-08-17T07:16:59.031959Z",
     "shell.execute_reply.started": "2023-08-17T07:16:58.999119Z",
     "shell.execute_reply": "2023-08-17T07:16:59.031103Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mEncoded with existing encoder.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "   label\n0      0\n1      0\n2      0\n3      0\n4      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "apply_label_encoding(labels, action='decode', encoder_name=\"embeddings_labels\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.197394Z",
     "end_time": "2023-08-19T11:34:58.385642Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:59.033209Z",
     "iopub.execute_input": "2023-08-17T07:16:59.033719Z",
     "iopub.status.idle": "2023-08-17T07:16:59.048020Z",
     "shell.execute_reply.started": "2023-08-17T07:16:59.033688Z",
     "shell.execute_reply": "2023-08-17T07:16:59.047152Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Acura_MDX', 'Acura_MDX', 'Acura_MDX', ..., 'ZIL_5301_Bychok',\n       'ZIL_5301_Bychok', 'ZIL_5301_Bychok'], dtype=object)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch Dataset to run model on"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.216340Z",
     "end_time": "2023-08-19T11:34:58.385642Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:59.068374Z",
     "iopub.execute_input": "2023-08-17T07:16:59.069151Z",
     "iopub.status.idle": "2023-08-17T07:16:59.078543Z",
     "shell.execute_reply.started": "2023-08-17T07:16:59.069113Z",
     "shell.execute_reply": "2023-08-17T07:16:59.077486Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_embeddings_bag, test_embeddings_bag, train_labels, test_labels = train_test_split(embeddings_bag, labels, random_state=config.seed, train_size=21790/24564, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.225446Z",
     "end_time": "2023-08-19T11:34:58.457907Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:59.079917Z",
     "iopub.execute_input": "2023-08-17T07:16:59.080696Z",
     "iopub.status.idle": "2023-08-17T07:16:59.179418Z",
     "shell.execute_reply.started": "2023-08-17T07:16:59.080663Z",
     "shell.execute_reply": "2023-08-17T07:16:59.178373Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# If we shuffle the data, we need to reset indexes\n",
    "train_labels.reset_index(drop=True, inplace=True)\n",
    "test_labels.reset_index(drop=True, inplace=True)\n",
    "test_embeddings_bag.reset_index(drop=True, inplace=True)\n",
    "train_embeddings_bag.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.288952Z",
     "end_time": "2023-08-19T11:34:58.457907Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:59.186002Z",
     "iopub.execute_input": "2023-08-17T07:16:59.186652Z",
     "iopub.status.idle": "2023-08-17T07:16:59.194051Z",
     "shell.execute_reply.started": "2023-08-17T07:16:59.186614Z",
     "shell.execute_reply": "2023-08-17T07:16:59.192949Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         1\n",
      "4         1\n",
      "...     ...\n",
      "2769    758\n",
      "2770    758\n",
      "2771    759\n",
      "2772    759\n",
      "2773    759\n",
      "\n",
      "[2774 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.301433Z",
     "end_time": "2023-08-19T11:34:58.457907Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feedforward model to process embeddings pairs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's the schema of our network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=embedding_size, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3, inplace=False),\n",
    "            nn.Linear(in_features=1024, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        square = (x1 - x2)**2\n",
    "        square = square.to(torch.float32)\n",
    "        # Pass the inputs through fully connected layers\n",
    "        output = self.fc(square)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:59.218805Z",
     "iopub.execute_input": "2023-08-17T07:16:59.219865Z",
     "iopub.status.idle": "2023-08-17T07:16:59.230192Z",
     "shell.execute_reply.started": "2023-08-17T07:16:59.219830Z",
     "shell.execute_reply": "2023-08-17T07:16:59.229207Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:38:35.210368Z",
     "end_time": "2023-08-19T17:38:35.268289Z"
    }
   },
   "execution_count": 185,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# But we will use trained and saved model\n",
    "# perceptron_model = SiameseNetwork(config.embedding_size)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:16:59.231726Z",
     "iopub.execute_input": "2023-08-17T07:16:59.232498Z",
     "iopub.status.idle": "2023-08-17T07:16:59.277423Z",
     "shell.execute_reply.started": "2023-08-17T07:16:59.232463Z",
     "shell.execute_reply": "2023-08-17T07:16:59.275732Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:36:27.071062Z",
     "end_time": "2023-08-19T17:36:27.193068Z"
    }
   },
   "execution_count": 179,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    # Load weights from previously trained\n",
    "    perceptron_model = torch.load(config.mlp_model_path, map_location=torch.device('cpu'))\n",
    "except FileNotFoundError:\n",
    "    print(\"No trained model found.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-17T07:17:42.826029Z",
     "iopub.execute_input": "2023-08-17T07:17:42.826414Z",
     "iopub.status.idle": "2023-08-17T07:17:42.841574Z",
     "shell.execute_reply.started": "2023-08-17T07:17:42.826385Z",
     "shell.execute_reply": "2023-08-17T07:17:42.839630Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:38:38.654246Z",
     "end_time": "2023-08-19T17:38:38.713536Z"
    }
   },
   "execution_count": 186,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quality metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For training tracking we will use accuracy and F1 score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "f1_score = MulticlassF1Score(num_classes=config.num_of_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-08-17T07:17:45.176587Z",
     "iopub.execute_input": "2023-08-17T07:17:45.176945Z",
     "iopub.status.idle": "2023-08-17T07:17:45.184963Z",
     "shell.execute_reply.started": "2023-08-17T07:17:45.176914Z",
     "shell.execute_reply": "2023-08-17T07:17:45.183358Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.369986Z",
     "end_time": "2023-08-19T11:34:58.515385Z"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "For model evaluation we will also use other metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "perceptron_model = perceptron_model.to(device)\n",
    "\n",
    "f1_score = f1_score.to(device)\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:36:39.890713Z",
     "end_time": "2023-08-19T17:36:40.011809Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label prediction based of K Nearest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How values match among nearest neighbors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.406343Z",
     "end_time": "2023-08-19T11:34:58.734762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=5, metric='cosine')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:34:58.457907Z",
     "end_time": "2023-08-19T11:34:58.783657Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We train Neighbors model on `train_embeddings_bag`, so the model will predict the indexes related with **that** array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "NearestNeighbors(metric='cosine')",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(train_embeddings_bag.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:56:59.212182Z",
     "end_time": "2023-08-19T11:56:59.407062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# found_nearest = neigh.kneighbors(torch.unsqueeze(r_embedding, dim=0).cpu().numpy())\n",
    "found_nearest = neigh.kneighbors(test_embeddings_bag, return_distance=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:43:24.613716Z",
     "end_time": "2023-08-19T11:43:28.493743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1      2      3      4\n",
      "0        11  11805   8577   8596  15828\n",
      "1      2295     11   2175   6554   2316\n",
      "2         2      3      0      1   4780\n",
      "3        25     23     17     19     15\n",
      "4        27     26     21   8508   8510\n",
      "...     ...    ...    ...    ...    ...\n",
      "2769  21749  21736   2979  21738  21737\n",
      "2770  21742  21738  21745  21741  21748\n",
      "2771  21780  21770  21765  21767  21771\n",
      "2772  21785   3554  21758   3259   3540\n",
      "2773  21788  21768  12483  18723  10177\n",
      "\n",
      "[2774 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(found_nearest))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:43:36.525076Z",
     "end_time": "2023-08-19T11:43:36.585376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2774/2774 [00:00<00:00, 9425.33row/s]\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_with_nearest(array_of_nearest: np.array):\n",
    "    neighbors = []\n",
    "    with tqdm(array_of_nearest, desc=\"Processing\",unit=\"row\") as process:\n",
    "        for row_of_nearest in process:\n",
    "            labels_of_closest = []\n",
    "            for nearest_label in row_of_nearest:\n",
    "                labels_of_closest.append(labels.iat[nearest_label, 0])  # Get scalar from current row and first column\n",
    "            neighbors.append(labels_of_closest)\n",
    "    label_array = pd.DataFrame(neighbors)\n",
    "    return label_array\n",
    "\n",
    "neighbors_labels = get_dataset_with_nearest(found_nearest)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:18.680537Z",
     "end_time": "2023-08-19T11:44:19.113600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "        0    1    2    3    4\n0       0  408  279  280  582\n1     138    0  131  229  138\n2       0    0    0    0  176\n3       1    1    1    1    1\n4       1    1    1  287  287\n...   ...  ...  ...  ...  ...\n2769  758  758  151  758  758\n2770  758  758  758  758  758\n2771  759  759  759  759  759\n2772  759  160  759  154  160\n2773  759  759  438  663  343\n\n[2774 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>408</td>\n      <td>279</td>\n      <td>280</td>\n      <td>582</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>138</td>\n      <td>0</td>\n      <td>131</td>\n      <td>229</td>\n      <td>138</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>176</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>287</td>\n      <td>287</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2769</th>\n      <td>758</td>\n      <td>758</td>\n      <td>151</td>\n      <td>758</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>2770</th>\n      <td>758</td>\n      <td>758</td>\n      <td>758</td>\n      <td>758</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>2771</th>\n      <td>759</td>\n      <td>759</td>\n      <td>759</td>\n      <td>759</td>\n      <td>759</td>\n    </tr>\n    <tr>\n      <th>2772</th>\n      <td>759</td>\n      <td>160</td>\n      <td>759</td>\n      <td>154</td>\n      <td>160</td>\n    </tr>\n    <tr>\n      <th>2773</th>\n      <td>759</td>\n      <td>759</td>\n      <td>438</td>\n      <td>663</td>\n      <td>343</td>\n    </tr>\n  </tbody>\n</table>\n<p>2774 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:20.226729Z",
     "end_time": "2023-08-19T11:44:20.290945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "0    756\n1    752\n2    750\n3    747\n4    749\ndtype: int64"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_labels.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:27.161445Z",
     "end_time": "2023-08-19T11:44:27.217344Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All labels are covered."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will check how do the neighbors labels match to each other."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def all_values_same(row):\n",
    "    return all(row == row[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:30.082920Z",
     "end_time": "2023-08-19T11:44:30.142652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def some_values_same(row, number_of_same=3):\n",
    "    unique_numbers = set(row)\n",
    "    all_numbers = list(row)\n",
    "    [all_numbers.remove(u) for u in unique_numbers]\n",
    "    # Now we can select any number - list contains only numbers that represent the majority.\n",
    "    try:\n",
    "        value_to_compare = all_numbers[0]\n",
    "    except IndexError:\n",
    "        value_to_compare = row[0]\n",
    "\n",
    "    return ((row == value_to_compare).sum() >= number_of_same)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:30.740187Z",
     "end_time": "2023-08-19T11:44:30.802658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "neighbors_labels['are_labels_same'] = neighbors_labels.apply(all_values_same, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:31.027717Z",
     "end_time": "2023-08-19T11:44:31.561880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "neighbors_labels['three_are_same'] = neighbors_labels.loc[:, neighbors_labels.columns[:-1]].apply(some_values_same, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:31.467943Z",
     "end_time": "2023-08-19T11:44:32.227521Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check how good our Neighbors model works"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "        0    1    2    3    4  are_labels_same  three_are_same\n0       0  408  279  280  582            False           False\n1     138    0  131  229  138            False           False\n2       0    0    0    0  176            False            True\n3       1    1    1    1    1             True            True\n4       1    1    1  287  287            False            True\n...   ...  ...  ...  ...  ...              ...             ...\n2769  758  758  151  758  758            False            True\n2770  758  758  758  758  758             True            True\n2771  759  759  759  759  759             True            True\n2772  759  160  759  154  160            False           False\n2773  759  759  438  663  343            False           False\n\n[2774 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>are_labels_same</th>\n      <th>three_are_same</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>408</td>\n      <td>279</td>\n      <td>280</td>\n      <td>582</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>138</td>\n      <td>0</td>\n      <td>131</td>\n      <td>229</td>\n      <td>138</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>176</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>287</td>\n      <td>287</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2769</th>\n      <td>758</td>\n      <td>758</td>\n      <td>151</td>\n      <td>758</td>\n      <td>758</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2770</th>\n      <td>758</td>\n      <td>758</td>\n      <td>758</td>\n      <td>758</td>\n      <td>758</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2771</th>\n      <td>759</td>\n      <td>759</td>\n      <td>759</td>\n      <td>759</td>\n      <td>759</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2772</th>\n      <td>759</td>\n      <td>160</td>\n      <td>759</td>\n      <td>154</td>\n      <td>160</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2773</th>\n      <td>759</td>\n      <td>759</td>\n      <td>438</td>\n      <td>663</td>\n      <td>343</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>2774 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:32.109716Z",
     "end_time": "2023-08-19T11:44:32.244541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 53.28046142754146% of data classes have all same class in its' nearest vectors\n"
     ]
    }
   ],
   "source": [
    "print(f\"In {len(neighbors_labels[neighbors_labels['are_labels_same']]) / len(neighbors_labels) * 100}% of data classes have all same class in its' nearest vectors\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:33.013551Z",
     "end_time": "2023-08-19T11:44:33.089498Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 86.58976207642394% of data classes have at least 3 of same class in its' nearest vectors\n"
     ]
    }
   ],
   "source": [
    "print(f\"In {len(neighbors_labels[neighbors_labels['three_are_same']]) / len(neighbors_labels) * 100}% of data classes have at least 3 of same class in its' nearest vectors\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:33.278310Z",
     "end_time": "2023-08-19T11:44:33.369252Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, when we have target object to predict label for, we can take some odd number of neighbors (e.g. $N=5$), and then do a Vote using majority label! It is enough to have at least $\\frac{N-1}{2}$ of same class to make a strong prediction. Let's see does it work at all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# embeddings_bag = embeddings_bag.to_numpy()\n",
    "# labels = labels.to_numpy()\n",
    "# labels = apply_label_encoding(labels, action='decode', encoder_name=\"embeddings_labels\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:30:54.780173Z",
     "end_time": "2023-08-19T08:30:54.869078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:44:41.002566Z",
     "end_time": "2023-08-19T11:44:41.042492Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def predict_with_nearest(all_nearest_indexes, labels):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, row in enumerate(tqdm(all_nearest_indexes)):\n",
    "        nearest_indexes = row\n",
    "        nearest_classes = [labels[n].item() for n in nearest_indexes]\n",
    "        counter = Counter(nearest_classes)\n",
    "        predicted_class = counter.most_common(1)[0][0]\n",
    "\n",
    "        target_label = labels[i]  # Actual class\n",
    "        correct += int(target_label == predicted_class)\n",
    "        total += 1\n",
    "    print_highlighted(f\"Accuracy is: {correct/total}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:30:54.806664Z",
     "end_time": "2023-08-19T08:30:54.900327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Here we get an array of size B x N, where B is a batch size we want to test at once; N is a number of neighbors (we will take all dataset)\n",
    "bag_of_nearest = neigh.kneighbors(test_embeddings_bag, return_distance=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:30:54.819543Z",
     "end_time": "2023-08-19T08:30:58.040648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bag_of_nearest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[203], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predict_with_nearest(\u001B[43mbag_of_nearest\u001B[49m, train_labels\u001B[38;5;241m.\u001B[39mto_numpy(),)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'bag_of_nearest' is not defined"
     ]
    }
   ],
   "source": [
    "predict_with_nearest(bag_of_nearest, train_labels.to_numpy(),)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:31:28.641347Z",
     "end_time": "2023-08-19T08:31:28.888920Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's a result on all embeddings, either familiar for our Backbone CNN model (MobileNet trained with Arcface) or not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "del bag_of_nearest\n",
    "del neighbors_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:31:32.261014Z",
     "end_time": "2023-08-19T08:31:32.299821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:31:34.029789Z",
     "end_time": "2023-08-19T08:31:34.092848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:31:34.224757Z",
     "end_time": "2023-08-19T08:31:34.297813Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test our Model by prediction the similarity between objects that are nearest in the vector area. For that case we will use our NearestNeighbors trained algorithm."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predicted_proba, target_labels \u001B[38;5;241m=\u001B[39m get_probabilities(model\u001B[38;5;241m=\u001B[39mperceptron_model, dataloader\u001B[38;5;241m=\u001B[39m\u001B[43mtest_dataloader\u001B[49m, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# predicted_proba, target_labels = get_probabilities(model=perceptron_model, dataloader=test_dataloader, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T07:18:06.396379Z",
     "end_time": "2023-08-18T07:18:08.707406Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing on real photos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will upload our backbone model to get embeddings of test photos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "config.embedding_model_path = 'saved_instances/ArcFace_mobilenet_v2.pth'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:57:22.327990Z",
     "end_time": "2023-08-19T11:57:22.394011Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def get_input_feature_size(classifier: nn.Sequential) -> int:\n",
    "    for module in classifier.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            return module.in_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:57:22.484422Z",
     "end_time": "2023-08-19T11:57:22.532888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def get_model(model_name='resnet18', from_path=None, pretrained=True,) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "        Multipurpose function to load the model. For our task we will use fully trained model. If you don't have such, you may\n",
    "    download any pretrained model cut last layer - you both `pretrained` and `get_embeddings` set to True.\n",
    "    :param model_name:\n",
    "    :param get_embeddings: whether to cut the classifier layer\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if from_path:\n",
    "        try:\n",
    "            model = torch.load(from_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            return model\n",
    "        except FileNotFoundError:\n",
    "            raise\n",
    "    elif model_name:\n",
    "        model = getattr(models, model_name) # We use builtin function\n",
    "        model = model(\n",
    "            weights=('DEFAULT' if pretrained else None)\n",
    "        )\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        # nn.Dropout(p=0.3, inplace=True),\n",
    "        nn.Linear(in_features=get_input_feature_size(model.classifier),\n",
    "                  out_features=config.embedding_size, bias=True\n",
    "                  ),\n",
    "\n",
    "    )\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:57:22.711940Z",
     "end_time": "2023-08-19T11:57:22.782837Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "embedding_model = get_model(\n",
    "    from_path=config.embedding_model_path,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T11:57:23.891574Z",
     "end_time": "2023-08-19T11:57:24.070323Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get embeddings online"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's build a test dataset of images. Then, we will pass them through the backbone and try to predict a label. So, we will use everything: backbone CNN model, KNeighbors model, Binary Classifier model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "config.test_images_path = '../data/val_dataset_segmented'\n",
    "config.test_labels = \"../data/val_labels.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T22:05:10.663992Z",
     "end_time": "2023-08-19T22:05:10.708361Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def get_file_path_by_id(file_id, dir=config.root):\n",
    "    return os.path.join(dir, str(file_id) + \".jpg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    # Only validation is needed.\n",
    "\n",
    "    \"val\": A.Compose([\n",
    "        #         A.ToRGB(),\n",
    "        A.Resize(config.image_dimension, config.image_dimension),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0\n",
    "        ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "class CustomImagesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame=None, images_path: os.path=None, labels_path:os.path=None, transform_images: A.Compose=None, encoder_name=None):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert (data is not None) or (labels_path is not None and images_path is not None)\n",
    "\n",
    "        if data is None:\n",
    "            data = pd.read_csv(labels_path)\n",
    "            data['file_path'] = data['id'].apply(get_file_path_by_id, dir=images_path)\n",
    "\n",
    "        self.images_paths = data['file_path']\n",
    "\n",
    "\n",
    "        self.encoder_name = encoder_name if encoder_name else self.__hash__()  # We use hash as a unique name\n",
    "        print_highlighted(f\"Label Encoder saved with id `{self.encoder_name}`\")\n",
    "        self.labels = apply_label_encoding(labels=data['label'], action='encode', encoder_name=self.encoder_name)\n",
    "\n",
    "        # self.labels = data['label']\n",
    "        #         self.indexes = data['id'].values\n",
    "        self.transform_images = transform_images\n",
    "        self.__set_dataset_len()\n",
    "\n",
    "    def __set_dataset_len(self):\n",
    "        self.length = self.labels.shape[0] # Number of rows\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        We calculate the len in another function, so that we are able to slice.\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, int]:\n",
    "        \"\"\" Function to return item by indexing the dataset \"\"\"\n",
    "\n",
    "        if not isinstance(index, int) and isinstance(index, slice):\n",
    "            # It's not an index, but slice.\n",
    "            # We will return the part of data by making a copy of the dataset\n",
    "            index: slice\n",
    "            self = deepcopy(self)\n",
    "            self.length = index.stop  # Cut the length of dataset.\n",
    "            self.labels = self.labels[:self.length]\n",
    "            return self\n",
    "        assert self.__len__() >= index\n",
    "\n",
    "        image = to_pil_image(read_image(self.images_paths[index]))\n",
    "        if self.transform_images:\n",
    "            # Albumentations requires us to convert image to Numpy Array\n",
    "            image = self.transform_images(image=np.array(image))['image']\n",
    "\n",
    "        label = self.labels[index]\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mLabel Encoder saved with id `test_labels`\u001B[0m\n",
      "\u001B[43mEncoded with existing encoder.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "test_images_dataset = CustomImagesDataset(images_path=config.test_images_path, labels_path=config.test_labels, transform_images=data_transforms['val'], encoder_name='test_labels')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T22:05:17.294270Z",
     "end_time": "2023-08-19T22:05:17.338463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "data": {
      "text/plain": "11"
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T22:05:40.450192Z",
     "end_time": "2023-08-19T22:05:40.504704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [],
   "source": [
    "config.batch_size = 320"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T22:05:47.017111Z",
     "end_time": "2023-08-19T22:05:47.062655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_images_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count() % 4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T22:05:48.370634Z",
     "end_time": "2023-08-19T22:05:48.440034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def predict_online(dataloader, all_labels, feature_extractor_model, neighbors_model, device):\n",
    "    feature_extractor_model = feature_extractor_model.to(device)\n",
    "    feature_extractor_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "\n",
    "    with tqdm(dataloader, desc=\"Processing...\",unit=\"batch\") as process:\n",
    "        for images, target_labels in process:\n",
    "            images = images.to(device)\n",
    "            target_labels = target_labels.to(device)\n",
    "            # print(labels)\n",
    "\n",
    "            embeddings = feature_extractor_model(images).cpu()\n",
    "\n",
    "            bag_of_nearest_indexes = neighbors_model.kneighbors(embeddings, return_distance=False)\n",
    "            # print(bag_of_nearest_indexes)\n",
    "            del images\n",
    "            del embeddings\n",
    "\n",
    "\n",
    "            # for i, row in enumerate(tqdm(bag_of_nearest_indexes, desc=\"|__Predicting...\")):\n",
    "            for i, row in enumerate(bag_of_nearest_indexes):\n",
    "\n",
    "                nearest_indexes = row\n",
    "                nearest_classes = [all_labels[n].item() for n in nearest_indexes]\n",
    "                counter = Counter(nearest_classes)\n",
    "                predicted_class = counter.most_common(1)[0][0]\n",
    "                #\n",
    "                target_label = target_labels[i]  # Actual class\n",
    "                correct += int(target_label == predicted_class)\n",
    "                total += 1\n",
    "                all_predictions.append(predicted_class)\n",
    "\n",
    "        # print(np.take(all_labels,bag_of_nearest), labels)\n",
    "        print_highlighted(f\"Accuracy is: {correct/total}\")\n",
    "\n",
    "    return np.array(all_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:15:39.362546Z",
     "end_time": "2023-08-19T17:15:39.423287Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 2/2 [00:06<00:00,  3.19s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mAccuracy is: 0.83\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_Y_pred = predict_online(test_dataloader, labels.to_numpy(), embedding_model, neigh, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:15:39.757197Z",
     "end_time": "2023-08-19T17:15:46.165026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[4.0977e-06],\n        [4.5946e-07],\n        [7.9427e-06],\n        [2.9541e-06],\n        [1.2626e-06],\n        [1.0746e-06],\n        [1.1124e-06],\n        [9.1576e-07],\n        [7.4756e-06],\n        [1.3007e-05]], grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_model(torch.rand(10, 512), torch.rand(1, 512))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T17:43:19.874568Z",
     "end_time": "2023-08-19T17:43:19.978855Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: while using Siamese Network, we are able to pass one vector as `X1` and array of vectors as `X2`. So, we can pass one target vector and batch of nearest vectors - thus we get batch of similarity ratio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.6600e-06],\n",
      "         [2.7041e-06],\n",
      "         [8.2067e-06],\n",
      "         [4.0064e-07],\n",
      "         [4.3008e-07]],\n",
      "\n",
      "        [[9.9791e-06],\n",
      "         [2.6468e-04],\n",
      "         [3.4462e-07],\n",
      "         [1.3662e-04],\n",
      "         [5.1698e-06]],\n",
      "\n",
      "        [[5.5825e-09],\n",
      "         [3.9484e-09],\n",
      "         [1.7595e-06],\n",
      "         [1.3264e-07],\n",
      "         [1.1600e-06]],\n",
      "\n",
      "        [[1.2489e-07],\n",
      "         [1.5809e-07],\n",
      "         [5.6568e-04],\n",
      "         [3.2742e-07],\n",
      "         [9.7062e-05]]])\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "k = 5\n",
    "with torch.no_grad():\n",
    "    print(perceptron_model(torch.rand(4, 1, 512), torch.rand(4, k, 512)).shape)\n",
    "del k"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T19:07:15.973945Z",
     "end_time": "2023-08-19T19:07:16.038510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "def get_probable_label(weights, labels) -> int:\n",
    "    \"\"\"\n",
    "    This function is supposed to process two vectors:\n",
    "    `labels` represents sequence of labels of neighbors, and values MAY REPEAT\n",
    "    `weights` show how probable each value is.\n",
    "    The main problem to solve here is that it might be two same labels in array (so it's more probable).\n",
    "    :param weights:\n",
    "    :param labels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    probs = defaultdict(float)\n",
    "    for i, label in enumerate(labels):\n",
    "        probs[label.item()] += weights[i].item()\n",
    "\n",
    "    label_with_max_proba, _ = max(probs.items(), key=lambda x: x[1])  # Iterate over values, but get the key.\n",
    "    return label_with_max_proba\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T21:53:21.444639Z",
     "end_time": "2023-08-19T21:53:21.484167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def predict_with_weighted_nearest(X: torch.tensor, backbone_model, binary_clf_model, device):\n",
    "    \"\"\"\n",
    "        Function to enhance the prediction of KNeighbors model. We still use nearest neighbors to get probable labels,\n",
    "    and then, we use Binary Classificator MLP to compare neighbors embeddings with our target image embedding.\n",
    "    :param X: image or sequence of images - normalized 3x256x256 vectors;\n",
    "    :param backbone_model: CNN network without classifier layer - to get image embedding;\n",
    "    :param binary_clf_model: embedding classifier that detects whether two vectors are of same class (label);\n",
    "    :param device:\n",
    "    :return: probabilities of predicted labels\n",
    "    \"\"\"\n",
    "    backbone_model = backbone_model.to(device)\n",
    "    binary_clf_model = binary_clf_model.to(device)\n",
    "\n",
    "    if X.dim() == 3:\n",
    "        # Means it's one image, not a batch\n",
    "        X = torch.unsqueeze(X, dim=0)  # Turn it into batch\n",
    "        print('unsqueezed.')\n",
    "    elif X.dim() == 4:\n",
    "        pass\n",
    "\n",
    "    embedding = backbone_model(X)  # This vector is two-dimensional as it is a batch\n",
    "\n",
    "    bag_of_nearest_indexes = neigh.kneighbors(embedding, return_distance=False)  # Shape is `B x k`, k are neighbors\n",
    "    # bag_of_nearest_indexes = torch.tensor(bag_of_nearest_indexes).to(device)\n",
    "    # print(bag_of_nearest_indexes)\n",
    "\n",
    "    # Now we select embeddings by their indexes. For the case of indexing array by another array, numpy.take (https://numpy.org/doc/stable/reference/generated/numpy.take.html) works fine.\n",
    "    # We're indexing the `N x 512` array by the `B x K` array, and the result is the `B x K x 512` array of embeddings.\n",
    "    # Try following to see:\n",
    "    # print(train_embeddings_bag.to_numpy().shape, bag_of_nearest_indexes.shape, np.take(train_embeddings_bag.to_numpy(), bag_of_nearest_indexes, axis=0).shape)\n",
    "\n",
    "    batch_of_nearest_vectors = np.take(train_embeddings_bag.to_numpy(), bag_of_nearest_indexes, axis=0)\n",
    "    batch_of_nearest_labels = torch.tensor(np.squeeze(np.take(train_labels.to_numpy(), bag_of_nearest_indexes, axis=0))) # Shape of (B, K)\n",
    "\n",
    "    # Note: `batch_of_nearest` is 3-dimensional. If we are to compare nearest with the target embedding,\n",
    "    # we have to adjust this vector to same dimension.\n",
    "    embedding = torch.unsqueeze(embedding, dim=1) # From shape (B, 512) to (B, 1, 512)\n",
    "    predicted_similarity = binary_clf_model(embedding, batch_of_nearest_vectors)\n",
    "    predicted_similarity = torch.squeeze(predicted_similarity)  # From (B, K, 1) to (B, K)\n",
    "\n",
    "    # Now we can get the highest probability, and apply it as our prediction. But there is also\n",
    "    # more stable way: to sum probabilities of same class firstly.\n",
    "\n",
    "    # We normalize the proba among the nearest (as they are too close originally), but it's not really necessary\n",
    "    predicted_similarity = F.normalize(predicted_similarity, dim=1)\n",
    "\n",
    "\n",
    "    # Now we are going to iterate over nearest to get most probable label per each item\n",
    "    predictions = []\n",
    "    for row_of_similarities, row_of_labels in zip(predicted_similarity, batch_of_nearest_labels):\n",
    "        predictions.append(get_probable_label(weights=row_of_similarities, labels=row_of_labels))\n",
    "    return torch.tensor(predictions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T21:53:21.647925Z",
     "end_time": "2023-08-19T21:53:21.720828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 1/1 [00:02<00:00,  2.18s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mAccuracy is: 0.6363636363636364\u001B[0m\n",
      "[(269, 269), (279, 596), (303, 303), (306, 306), (308, 308), (316, 316), (354, 354), (388, 390), (457, 458), (487, 601), (516, 516)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "preds = []\n",
    "all_labels = []\n",
    "with tqdm(test_dataloader, desc=\"Processing...\",unit=\"batch\") as process:\n",
    "    for x, labels in process:\n",
    "        y_pred = predict_with_weighted_nearest(X=x, backbone_model=embedding_model, binary_clf_model=perceptron_model, device=device)\n",
    "        correct += (labels == y_pred).int().sum().item()\n",
    "        total += labels.size(0)\n",
    "        preds.extend(list(y_pred.cpu().numpy()))\n",
    "        all_labels.extend(list(labels.cpu().numpy()))\n",
    "\n",
    "print_highlighted(f\"Accuracy is: {correct/total}\")\n",
    "print(list(zip(all_labels, preds)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T22:08:22.538996Z",
     "end_time": "2023-08-19T22:08:24.738047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "data": {
      "text/plain": "<function __main__.predict_with_weighted_nearest(X: <built-in method tensor of type object at 0x00007FFCC690C560>, backbone_model, binary_clf_model, device)>"
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_with_weighted_nearest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T21:40:02.839907Z",
     "end_time": "2023-08-19T21:40:02.891803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1, 3, 2, 2).dim()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T16:18:26.484043Z",
     "end_time": "2023-08-19T16:18:26.524977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label:  411\n",
      "Index is 11855; got vector of shape (512,); similarity is:[0.99997866].Label is 411\n",
      "Index is 11858; got vector of shape (512,); similarity is:[0.99949944].Label is 411\n",
      "Index is 11859; got vector of shape (512,); similarity is:[0.99895465].Label is 411\n",
      "Index is 21139; got vector of shape (512,); similarity is:[0.992599].Label is 740\n",
      "Index is 11853; got vector of shape (512,); similarity is:[0.9963295].Label is 411\n"
     ]
    }
   ],
   "source": [
    "temporary_variables()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T15:49:29.037600Z",
     "end_time": "2023-08-19T15:49:29.574139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n          ...,\n          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n \n         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n          ...,\n          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n \n         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n          ...,\n          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n 0)"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T15:43:58.591383Z",
     "end_time": "2023-08-19T15:43:58.989026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 279\n",
      "279 303\n",
      "303 306\n",
      "306 308\n",
      "308 316\n",
      "316 354\n",
      "354 388\n",
      "388 457\n",
      "457 487\n",
      "487 516\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(test_images_dataset) -1:\n",
    "    print(test_images_dataset[i][1], test_images_dataset[i+1][1])\n",
    "    i+=1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:59:36.841513Z",
     "end_time": "2023-08-19T08:59:37.030284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ../data/images/test\\1.jpg\n",
      "1      ../data/images/test\\2.jpg\n",
      "2      ../data/images/test\\3.jpg\n",
      "3      ../data/images/test\\4.jpg\n",
      "4      ../data/images/test\\5.jpg\n",
      "5      ../data/images/test\\6.jpg\n",
      "6      ../data/images/test\\7.jpg\n",
      "7      ../data/images/test\\8.jpg\n",
      "8      ../data/images/test\\9.jpg\n",
      "9     ../data/images/test\\10.jpg\n",
      "10    ../data/images/test\\11.jpg\n",
      "Name: file_path, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_images_dataset.images_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-19T08:45:54.361147Z",
     "end_time": "2023-08-19T08:45:54.399106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real testing on the photos from Internet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will repeat this experiment with real photos from Internet. No models were trained on them"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
